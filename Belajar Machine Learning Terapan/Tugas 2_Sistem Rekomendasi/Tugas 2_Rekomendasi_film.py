# -*- coding: utf-8 -*-
"""Rekomendasi Film.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_V18QqNKmg9bBK3onZZxGO9OfZ-xQ94m

# **Project Sistem Rekomendasi**

## Tujuan dan Manfaat Proyek

**Tujuan utama** dari proyek ini adalah untuk membangun sebuah sistem rekomendasi film yang dapat meningkatkan keterlibatan (engagement) pengguna dan memperpanjang durasi mereka di platform. Kami ingin menyediakan rekomendasi yang sangat personal dan akurat, yang terasa seperti kurasi dari seorang ahli film.

**Manfaat langsung** dari pencapaian tujuan ini adalah:

* Peningkatan Retensi Pengguna: Pengguna yang merasa platform memahami selera mereka cenderung akan kembali lagi dan tidak beralih ke layanan lain.

* Optimalisasi Konten: Wawasan dari model dapat membantu tim konten dalam mengambil keputusan yang didukung data tentang film apa yang harus ditambahkan ke katalog.

* Peluang Monetisasi: Durasi tontonan yang lebih lama dan tingkat kunjungan yang lebih sering membuka peluang untuk pendapatan dari iklan atau peningkatan langganan.

#Import Data

Mengimpor semua pustaka (libraries) Python yang dibutuhkan untuk proyek.

`pandas`: Untuk memanipulasi dan menganalisis data dalam format tabel (DataFrame).

`sklearn.feature_extraction.text.TfidfVectorizer`: Untuk mengubah data teks (genre film) menjadi vektor numerik menggunakan metode TF-IDF. Ini adalah inti dari model content-based.

`sklearn.metrics.pairwise.cosine_similarity`: Untuk menghitung kemiripan antar film berdasarkan vektor genre mereka.

`fastai.collab & fastai.tabular.all`: Pustaka tingkat tinggi yang mempermudah pembuatan model collaborative filtering dengan cepat.
"""

# Import pustaka yang diperlukan
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# Import pustaka yang diperlukan
import pandas as pd
from fastai.collab import *
from fastai.tabular.all import *
from pathlib import Path

"""Perintah ini menggunakan Git untuk mengkloning (mengunduh) sebuah repositori dari GitHub. Repositori ini berisi dataset yang akan digunakan (`movies.csv, ratings.csv`, dll.). File-file tersebut akan disalin ke lingkungan kerja notebook."""

#Clone repository dari github untuk mengakses dataset yang telah diunggah di github sebelumnya
!git clone https://github.com/Andishafira/Dicoding.git

"""Kode ini mendefinisikan lokasi (path) dari empat file CSV yang baru saja diunduh dan memuatnya ke dalam DataFrame pandas.

`df_movie`: Berisi informasi film (movieId, title, genres).

`df_ratings`: Berisi data rating yang diberikan pengguna ke film (userId, movieId, rating).

`df_tags dan df_links`: Data tambahan yang tidak digunakan dalam model akhir di notebook ini.
"""

#Inisialisasi path dari masing masing csv

df_movie_path = "/content/Dicoding/Belajar Machine Learning Terapan/Tugas 2_Sistem Rekomendasi/dataset/movies.csv"
df_ratings_path = "/content/Dicoding/Belajar Machine Learning Terapan/Tugas 2_Sistem Rekomendasi/dataset/ratings.csv"
df_tags_path = "/content/Dicoding/Belajar Machine Learning Terapan/Tugas 2_Sistem Rekomendasi/dataset/tags.csv"
df_links_path = "/content/Dicoding/Belajar Machine Learning Terapan/Tugas 2_Sistem Rekomendasi/dataset/links.csv"

df_movie = pd.read_csv(df_movie_path)
df_ratings = pd.read_csv(df_ratings_path)
df_tags = pd.read_csv(df_tags_path)
df_links = pd.read_csv(df_links_path)

"""Kode ini digunakan untuk melakukan analisis data eksplorasi (EDA) dasar untuk memahami isi dataset.

`df_movie.head() & df_ratings.head()`: Menampilkan 5 baris pertama dari tabel film dan rating untuk melihat struktur datanya.

`df_movie.info() & df_ratings.info()`: Memberikan ringkasan teknis tentang DataFrame, seperti jumlah data, nama kolom, dan tipe datanya. Ini berguna untuk memeriksa apakah ada data yang hilang (missing values).

`len(df_movie['genres'].unique())`: Menghitung jumlah kombinasi genre yang unik.

`all_genres.value_counts().head(10)`: Memisahkan genre yang digabung dengan | (misalnya, "Adventure|Animation|Children") menjadi genre individual, lalu menghitung dan menampilkan 10 genre paling umum di seluruh dataset (Drama, Comedy, Thriller, dll.).
"""

# Menampilkan 5 baris pertama dari movies_df
print("--- 5 baris pertama dari movies.csv ---")
print(df_movie.head())

# Menampilkan informasi kolom dan tipe data dari movies_df
print("\n--- Informasi dataframe movies_df ---")
print(df_movie.info())

# Menampilkan 5 baris pertama dari ratings_df
print("\n--- 5 baris pertama dari ratings.csv ---")
print(df_ratings.head())

# Menampilkan informasi kolom dan tipe data dari ratings_df
print("\n--- Informasi dataframe ratings_df ---")
print(df_ratings.info())

# Memeriksa jumlah nilai unik pada kolom 'genres'
print("\n--- Jumlah genre unik ---")
print(len(df_movie['genres'].unique()))

# Mengambil 10 genre teratas
print("\n--- 10 genre teratas ---")
# Kita akan memisahkan genre terlebih dahulu untuk mendapatkan gambaran yang lebih akurat
all_genres = df_movie['genres'].str.split('|', expand=True).stack().reset_index(level=1, drop=True)
print(all_genres.value_counts().head(10))

"""#Preprocessing Data"""

# Gabungkan data ratings dan movies
ratings = df_ratings.merge(df_movie)

"""Tabel `df_ratings` dan `df_movie` digabungkan menjadi satu DataFrame baru bernama `ratings`. Penggabungan ini dilakukan berdasarkan kolom `movieId` yang ada di kedua tabel. Hasilnya adalah sebuah tabel yang berisi `userId, rating, title,` dan `genres` dalam satu baris, yang memudahkan proses pelatihan model."""

ratings.head()

#Membagi Data
#split ratings to train df and test df (80:20)
from sklearn.model_selection import train_test_split
train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)

"""Dataset ratings dibagi menjadi dua bagian:

* **Data Latih (train_df)**: 80% dari data, digunakan untuk melatih model.

* **Data Uji (test_df)**: 20% dari data, digunakan untuk mengevaluasi seberapa baik performa model pada data yang belum pernah dilihat sebelumnya.

#Train Model

Sel ini adalah inti dari pemodelan, di mana dua jenis sistem rekomendasi dibangun.

1. **Model Collaborative Filtering** (dengan fastai):

`CollabDataLoaders.from_df`: Mempersiapkan data latih ke dalam format yang dibutuhkan oleh fastai.

`collab_learner`: Membuat model collaborative filtering. Model ini belajar pola dari interaksi pengguna-film secara keseluruhan.

`learn.fit_one_cycle(5, 5e-3)`: Memulai proses pelatihan model selama 5 epoch (siklus). Output tabel menunjukkan bahwa loss (kesalahan) pada data validasi semakin menurun, yang menandakan model sedang belajar.

2. **Model Content-Based Filtering** (dengan scikit-learn):

`TfidfVectorizer`: Mengonversi kolom genres dari setiap film menjadi representasi angka (vektor). Film dengan genre serupa akan memiliki vektor yang mirip.

`cosine_similarity`: Menghitung skor kemiripan (antara -1 dan 1) untuk setiap pasang film berdasarkan vektor genre mereka. Hasilnya adalah matriks cosine_sim yang menyimpan skor ini.
"""

# --- Model Collaborative Filtering (fastai) ---
# Persiapan data loaders
dls = CollabDataLoaders.from_df(
    train_df,
    user_name='userId',
    item_name='title',
    rating_name='rating',
    bs=64
)

# Latih model
learn = collab_learner(dls, n_factors=50, y_range=(0.5, 5.5), metrics=rmse)
learn.fit_one_cycle(5, 5e-3)

# --- Model Content-based (berbasis genre) ---
# Menggabungkan semua genre menjadi satu kolom string untuk vektorisasi
# genres_df = df_movie.drop(columns=['movieId','title'])
# genres_df['genres'] = genres_df.iloc[:, 1:].apply(
#     lambda row: '|'.join([col for col, val in row.items() if val == 1]), axis=1
# )

# Use the existing 'genres' column from df_movie directly
genres_data = df_movie['genres']

# Inisialisasi TfidfVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

tfidf_vectorizer = TfidfVectorizer(stop_words='english')
# Use the corrected genres_data for fitting and transforming
tfidf_matrix = tfidf_vectorizer.fit_transform(genres_data)

# Hitung Cosine Similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""##Membuat Model Hybrid

Sel ini mendefinisikan fungsi `get_hybrid_recommendations` yang menggabungkan kekuatan kedua model sebelumnya.

1. Mendapatkan Film yang Belum Ditonton: Fungsi ini mengambil `user_id` dan mencari semua film yang belum pernah ia tonton.

2. Prediksi Rating (Collaborative): Model `fastai` digunakan untuk memprediksi rating yang mungkin akan diberikan pengguna pada film-film yang belum ia tonton.

3. Mencari Film Favorit (Benih Content-Based): Fungsi ini mencari film dengan rating tertinggi yang pernah diberikan oleh pengguna. Film ini akan menjadi "benih" untuk mencari film lain yang genrenya mirip.

4. Skor Kemiripan Genre (Content-Based): Berdasarkan film "benih" tadi, fungsi ini mengambil skor kemiripan genre dari matriks `cosine_sim` untuk semua film lainnya.

5. Menghitung Skor Hibrida: Skor akhir dihitung dengan menggabungkan prediksi rating (dari model collaborative) dan skor kemiripan genre (dari model content-based) menggunakan bobot tertentu (`collaborative_weight dan content_weight`).

6. Mengembalikan Top-N Rekomendasi: Fungsi mengembalikan daftar film teratas berdasarkan skor hibrida tertinggi.
"""

def get_hybrid_recommendations(user_id, num_recommendations=10, collaborative_weight=0.6, content_weight=0.4):
    """
    Memberikan rekomendasi film hibrida untuk pengguna tertentu.

    Fungsi ini menggabungkan:
    1. Prediksi rating dari model Collaborative Filtering.
    2. Kemiripan genre dari model Content-based Filtering.

    Args:
        user_id (int): ID pengguna.
        num_recommendations (int): Jumlah rekomendasi yang diinginkan.
        collaborative_weight (float): Bobot untuk skor collaborative (prediksi rating).
        content_weight (float): Bobot untuk skor content-based (kemiripan genre).

    Returns:
        pd.DataFrame: Daftar film yang direkomendasikan dengan skor hibrida.
    """
    # 1. Mendapatkan daftar film yang belum pernah ditonton pengguna
    user_rated_movies = train_df[train_df['userId'] == user_id]['title'].tolist()
    all_movies_titles = df_movie['title'].tolist()
    unrated_movies = [title for title in all_movies_titles if title not in user_rated_movies]

    # Pilih film acak dari yang belum ditonton untuk diprediksi (untuk efisiensi)
    unrated_movies_sample = pd.Series(unrated_movies).tolist()

    # 2. Menggunakan model Collaborative untuk memprediksi rating
    user_tensor = torch.tensor([dls.classes['userId'].o2i[user_id]] * len(unrated_movies_sample))
    movie_titles_tensor = torch.tensor([dls.classes['title'].o2i[title] for title in unrated_movies_sample])

    # Concatenate user and movie tensors
    collab_input = torch.stack([user_tensor, movie_titles_tensor], dim=1)

    with torch.no_grad():
        collab_preds = learn.model.forward(collab_input)
    collab_preds = collab_preds.numpy()

    collab_df = pd.DataFrame({'title': unrated_movies_sample, 'predicted_rating': collab_preds.flatten()}) # Flatten to match the shape

    # 3. Mendapatkan film favorit pengguna (sebagai "benih" untuk model Content-based)
    # Kita ambil 5 film dengan rating tertinggi dari pengguna
    user_top_movies = train_df[(train_df['userId'] == user_id) & (train_df['rating'] >= 4)].sort_values(by='rating', ascending=False).head(5)

    if user_top_movies.empty:
        print("Pengguna ini belum memiliki rating film tinggi. Menggunakan rekomendasi Collaborative saja.")
        # Add content similarity scores of 0 for all recommendations if no top movies
        collab_df['content_sim_score'] = 0.0
        collab_df['hybrid_score'] = collaborative_weight * collab_df['predicted_rating']
        return collab_df.sort_values(by='hybrid_score', ascending=False).head(num_recommendations)


    seed_movie_title = user_top_movies['title'].iloc[0]

    # 4. Menghitung skor kemiripan konten untuk re-ranking
    # Dapatkan indeks film 'seed'
    seed_movie_idx = df_movie[df_movie['title'] == seed_movie_title].index[0]

    # Dapatkan skor kemiripan dari film seed dengan semua film lain
    content_sim_scores = cosine_sim[seed_movie_idx]

    # Gabungkan dengan dataframe prediksi
    hybrid_recs = collab_df.merge(df_movie[['title']], on='title')
    hybrid_recs['content_sim_score'] = hybrid_recs['title'].apply(
        lambda x: content_sim_scores[df_movie[df_movie['title'] == x].index[0]]
    )

    # 5. Menggabungkan skor untuk mendapatkan skor hibrida
    hybrid_recs['hybrid_score'] = (
        collaborative_weight * hybrid_recs['predicted_rating'] +
        content_weight * (hybrid_recs['content_sim_score'] * 5) # Kalikan dengan 5 agar skalanya mirip
    )

    # Urutkan berdasarkan skor hibrida dan tampilkan hasilnya
    final_recs = hybrid_recs.sort_values(by='hybrid_score', ascending=False).head(num_recommendations)
    return final_recs[['title', 'hybrid_score', 'predicted_rating', 'content_sim_score']]

"""##Contoh Testing

Kode ini menunjukkan cara menggunakan fungsi hibrida. Fungsi `get_hybrid_recommendations` dipanggil untuk pengguna dengan ID 197. Hasilnya adalah 10 film yang direkomendasikan, diurutkan berdasarkan `hybrid_score` tertinggi.
"""

# Contoh penggunaan:
user_id_to_recommend = 197
print(f"--- Rekomendasi Hibrida untuk Pengguna {user_id_to_recommend} ---")
recommendations = get_hybrid_recommendations(user_id_to_recommend)
print(recommendations)

"""#Evaluasi Model

Untuk mengukur kinerja model secara objektif, fungsi `evaluate_hybrid_recommender` dibuat.

1. **Metrik** : Fungsi ini menggunakan **Precision@k** (berapa persen dari k rekomendasi yang relevan) dan **Recall@k**(berapa persen dari total film relevan yang berhasil direkomendasikan).

2. **Proses** : Fungsi ini berjalan pada data uji (`test_df`). Untuk setiap pengguna sampel:

    * Menentukan "film relevan" (film yang diberi rating tinggi, misalnya >= 4.0).

    * Menghasilkan 10 rekomendasi teratas menggunakan fungsi hibrida.

    * Membandingkan film yang direkomendasikan dengan film yang relevan untuk menghitung "hits".

    * Menghitung Precision dan Recall.

3. **Hasil** : Sel terakhir menjalankan evaluasi dan mencetak Rata-rata Precision@10: 0.0380 dan Rata-rata Recall@10: 0.0285.
"""

def evaluate_hybrid_recommender(model, ratings_df, test_df, k=10, min_rating=4.0):
    """
    Mengevaluasi sistem rekomendasi hibrida menggunakan metrik Precision@k dan Recall@k.

    Args:
        model: Model fastai yang sudah dilatih.
        ratings_df (pd.DataFrame): Dataframe rating lengkap.
        k (int): Jumlah item teratas yang akan dipertimbangkan untuk rekomendasi.
        min_rating (float): Rating minimum untuk dianggap "relevan".

    Returns:
        tuple: Precision@k dan Recall@k rata-rata.
    """
    all_users = test_df['userId'].unique()
    all_movies = ratings_df['title'].unique()

    precision_scores = []
    recall_scores = []

    # Ambil sampel beberapa pengguna untuk evaluasi yang efisien
    sample_users = pd.Series(all_users).sample(n=min(50, len(all_users)), random_state=42)

    for user_id in sample_users:
        # Dapatkan film yang sudah dirating pengguna
        user_ratings = test_df[test_df['userId'] == user_id]

        # Pisahkan film relevan (rating tinggi) dari film yang tidak relevan
        relevant_movies = user_ratings[user_ratings['rating'] >= min_rating]['title'].tolist()
        print(f"Pengguna {user_id} memiliki {len(relevant_movies)} film relevan.")
        # Dapatkan rekomendasi hibrida
        # Karena ini simulasi, kita gunakan fungsi rekomendasi sebelumnya
        recommendations = get_hybrid_recommendations(user_id, num_recommendations=k)
        print(f"Rekomendasi untuk pengguna {user_id}: {recommendations['title'].tolist()}")
        if recommendations is None:
            continue

        recommended_movies = recommendations['title'].tolist()

        # Hitung irisan antara film yang direkomendasikan dan film yang relevan
        hits = len(set(recommended_movies) & set(relevant_movies))
        print(f"Pengguna {user_id} memiliki {hits} hits.")
        # Hitung Precision@k
        precision = hits / len(recommended_movies) if len(recommended_movies) > 0 else 0
        precision_scores.append(precision)

        # Hitung Recall@k
        recall = hits / len(relevant_movies) if len(relevant_movies) > 0 else 0
        recall_scores.append(recall)

    # Hitung rata-rata Precision dan Recall
    avg_precision = sum(precision_scores) / len(precision_scores) if precision_scores else 0
    avg_recall = sum(recall_scores) / len(recall_scores) if recall_scores else 0

    return avg_precision, avg_recall

# Uji coba dengan k=10 dan rating relevan >= 4
avg_prec, avg_rec = evaluate_hybrid_recommender(learn, ratings, test_df, k=10, min_rating=4.0)
print(f"Rata-rata Precision@{10}: {avg_prec:.4f}")
print(f"Rata-rata Recall@{10}: {avg_rec:.4f}")

"""**Dari data yang disajikan, terlihat bahwa kinerja sistem rekomendasi ini, yang diukur dengan metrik Precision@k dan Recall@k pada k=10, masih sangat rendah.**

* Rata-rata Precision@10 sebesar 0.0380 menunjukkan bahwa, rata-rata, hanya sekitar 3.8% dari film yang direkomendasikan kepada pengguna adalah film yang relevan (film yang mereka sukai). Dengan kata lain, dari 10 film yang direkomendasikan, hanya sekitar 0.38 film (kurang dari satu) yang benar-benar relevan.

* Rata-rata Recall@10 sebesar 0.0285 menunjukkan bahwa, rata-rata, sistem hanya berhasil menemukan sekitar 2.85% dari total film relevan yang disukai pengguna. Ini berarti sistem gagal menemukan sebagian besar film relevan yang ada dalam data pengguna.

Meskipun model ini berhasil memberikan rekomendasi yang terlihat masuk akal secara tematis (misalnya, rekomendasi film-film aksi/sci-fi untuk Pengguna 582 dan 599, atau film kriminal untuk Pengguna 215), jumlah "hits" (film yang direkomendasikan dan juga relevan) sangat sedikit. Dari 32 pengguna yang dievaluasi, hanya 9 pengguna yang mendapatkan setidaknya satu film relevan di antara 10 rekomendasi teratas mereka.

**Analisis Lebih Lanjut**

Hasil ini menunjukkan bahwa ada beberapa area yang perlu diperbaiki:

* Keterbatasan Data: Jumlah pengguna dan film yang digunakan untuk evaluasi ini mungkin tidak cukup besar untuk memberikan gambaran yang akurat. Selain itu, sebaran data rating mungkin tidak merata, menyebabkan beberapa pengguna memiliki sedikit atau bahkan nol film relevan (seperti Pengguna 207 dan 496).

* Masalah Cold-Start: Sebagian besar pengguna dalam evaluasi ini (seperti Pengguna 428, 215, 461, 197, dst.) memiliki hits nol. Ini bisa menjadi indikasi masalah cold-start, di mana model tidak memiliki cukup data riwayat rating untuk pengguna tersebut, sehingga rekomendasinya tidak akurat.

* Bobot Model Hibrida: Bobot yang diberikan pada model Collaborative dan Content-based (jika ini adalah model hibrida) mungkin tidak optimal. Model mungkin terlalu condong ke salah satu sisi, sehingga gagal memanfaatkan kekuatan gabungan dari kedua pendekatan.

* Definisi "Relevan": Mungkin ada masalah dalam definisi "film relevan". Jika hanya film dengan rating 4 atau 5 yang dianggap relevan, model mungkin kesulitan jika sebagian besar rating pengguna berada di angka 3.

Secara keseluruhan, meskipun proyek ini berhasil membangun sebuah alur kerja rekomendasi, hasil evaluasi menunjukkan bahwa model ini belum siap untuk digunakan di lingkungan produksi. Diperlukan iterasi lebih lanjut pada model, data, dan strategi evaluasi untuk meningkatkan performa secara signifikan.

# **Implementasi Sistem Rekomendasi**

Proyek ini telah berhasil mengintegrasikan dua pendekatan rekomendasi yang berbeda untuk mengatasi keterbatasan masing-masing model.

**Content-based Filtering**: Model ini berfungsi dengan baik untuk mengatasi masalah cold-start—memberikan rekomendasi yang relevan kepada pengguna baru atau untuk film yang baru ditambahkan. Model ini menggunakan metadata film seperti genre dan tag untuk menemukan kemiripan. Kelemahan utamanya adalah ia cenderung merekomendasikan film yang terlalu mirip dengan apa yang sudah disukai pengguna, membatasi penemuan konten baru.

**Collaborative Filtering**: Menggunakan data rating dari pengguna, model ini mampu menemukan pola-pola tersembunyi dan mengidentifikasi film yang disukai oleh komunitas pengguna dengan selera serupa. Model ini sangat efektif dalam memberikan rekomendasi yang tidak terduga, atau serendipity. Namun, model ini tidak dapat berfungsi tanpa riwayat interaksi pengguna yang memadai, menjadikannya rentan terhadap masalah cold-start.

Dengan menggabungkan kedua model ini menjadi sistem hibrida, kita mendapatkan yang terbaik dari kedua dunia. Kami menggunakan model Collaborative Filtering untuk memprediksi film-film teratas yang mungkin disukai pengguna, lalu menggunakan model Content-based untuk memprioritaskan film-film tersebut berdasarkan kemiripan konten. Proses re-ranking ini memastikan bahwa rekomendasi tidak hanya akurat (berkat Collaborative) tetapi juga relevan dan personal (berkat Content-based).

## Strategi Bisnis

Sistem hibrida ini memiliki potensi besar untuk diintegrasikan ke dalam operasi bisnis. Berikut adalah beberapa strategi utama:

* Personalisasi Halaman Utama: Rekomendasi paling relevan akan ditampilkan di halaman utama, memastikan pengguna langsung disambut dengan konten yang mereka sukai. Ini dapat meningkatkan rata-rata sesi pengguna dan menurunkan tingkat bounce rate.

* Fitur "Lebih seperti ini": Di halaman detail film, pengguna akan melihat daftar film yang mirip secara tematis. Fitur ini dapat meminimalkan waktu yang dihabiskan pengguna untuk mencari konten dan mendorong mereka untuk terus menonton.

* Kampanye Pemasaran yang Ditargetkan: Model dapat digunakan untuk mengidentifikasi film-film yang mungkin disukai oleh pengguna yang tidak aktif. Rekomendasi yang dipersonalisasi dapat dikirim melalui email atau notifikasi untuk mendorong mereka kembali ke platform.

* Onboarding Pengguna Baru: Saat pengguna pertama kali mendaftar, mereka dapat diminta untuk memberi rating pada beberapa film. Sistem dapat menggunakan model Content-based untuk memberikan rekomendasi instan, menciptakan pengalaman yang menarik sejak awal.

## Kesimpulan

Secara keseluruhan, meskipun proyek ini berhasil membangun alur kerja rekomendasi, hasil evaluasi menunjukkan adanya kebutuhan mendesak untuk mengoptimalkan model, menyesuaikan bobot hibrida, dan mempertimbangkan strategi yang lebih efektif untuk mengatasi pengguna dengan riwayat rating yang minim.
"""